"""ç”¨DeepSeekå°†å¼ æ¨æ°´æ–‡æœ¬æ”¹å†™ä¸ºç®€å•ç°ä»£ç™½è¯æ–‡

æ”¯æŒæ–­ç‚¹ç»­ä¼ åŠŸèƒ½
"""

import argparse
import json
import requests
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

# System promptï¼šæŒ‡å¯¼APIæ”¹å†™ä¸ºç°ä»£ç™½è¯
REWRITE_SYSTEM = """# Role
ä½ æ˜¯ä¸€ä¸ªåˆçº§çš„ã€ç¼ºä¹æ–‡å­¦ç´ å…»çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚

# Task
å°†æä¾›çš„ã€æ–‡å­¦åŸè‘—ã€‘æ”¹å†™æˆä¸€æ®µå…¸å‹çš„ã€AI ç”Ÿæˆå¼ç™½è¯ã€‘ã€‚

# Rules (æ ¸å¿ƒé£æ ¼æŒ‡å—)
1. **å…¸å‹çš„ AI ç¿»è¯‘è…”**ï¼š
   - å¤šç”¨"è¢«"ã€"å…³äº"ã€"è¿›è¡Œ"ã€"ä½œå‡º"ç­‰è™šè¯ã€‚
   - å¥å¼è¦é•¿ä¸”æ­»æ¿ï¼ˆä¾‹ï¼šå°†"ä»–éª‚ç€èµ°äº†"æ”¹ä¸º"ä»–å¸¦ç€æ„¤æ€’çš„æƒ…ç»ªç¦»å¼€äº†ç°åœº"ï¼‰ã€‚
2. **é€»è¾‘åˆ—è¡¨åŒ–ï¼ˆå¯é€‰ï¼‰**ï¼š
   - å°è¯•ç”¨"é¦–å…ˆã€å…¶æ¬¡ã€æœ€å"æˆ–è€…"ç¬¬ä¸€ã€ç¬¬äºŒ"æ¥æ‹†è§£åŸè‘—çš„æƒ…èŠ‚ã€‚
3. **è¯æ±‡è´«ä¹ä¸”é‡å¤**ï¼š
   - é‡å¤ä½¿ç”¨"éå¸¸"ã€"ç‰¹åˆ«"ã€"è¡¨ç°å‡º"ã€"æ˜¾ç¤ºäº†"ç­‰ä¸‡é‡‘æ²¹è¯æ±‡ã€‚
   - ç»å¯¹ç¦æ­¢ä»»ä½•æ–‡å­¦æ„è±¡ï¼Œåªå‡†æè¿°äº‹å®ã€‚
4. **è¿‡åº¦è§£é‡Šï¼ˆæœºæ¢°æ„Ÿï¼‰**ï¼š
   - åƒè¯´æ˜ä¹¦ä¸€æ ·è§£é‡ŠåŸè‘—ä¸­çš„åŠ¨ä½œï¼ˆä¾‹ï¼šå°†"ä¸€æ–åˆ°åœ°"æ”¹ä¸º"åšå‡ºäº†ä¸€ä¸ªå‘ä¸‹å¼¯è…° 90 åº¦çš„èº«ä½“åŠ¨ä½œä»¥ç¤ºå°Šé‡"ï¼‰ã€‚

# Output Format
ç›´æ¥è¾“å‡ºé‚£æ®µå……æ»¡"æœºæ¢°å‘³"å’Œ"ç¿»è¯‘è…”"çš„ç™½è¯æ–‡ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚"""

USER_TEMPLATE = "è¯·å°†ä»¥ä¸‹æ–‡æœ¬æ”¹å†™ä¸ºç®€å•çš„ç°ä»£ç™½è¯æ–‡ï¼Œè¦æ±‚æ–‡ç›²ä¹Ÿèƒ½è¯»æ‡‚ï¼Œå»æ‰æå†™ï¼š\n\n{text}"

# System promptï¼šç”¨äºæœªæ¥fine-tuningï¼ŒæŒ‡å¯¼æ¨¡å‹å°†ç™½è¯æ–‡å˜å¾—é›…è‡´
TRAIN_SYSTEM = """ä½ æ˜¯ä¸€åä¼˜é›…çš„æ–‡å­¦æ”¹å†™ä½œå®¶ï¼Œæ“…é•¿æŠŠç°ä»£ç™½è¯æ¶¦è‰²æˆæ›´è®²ç©¶ã€æ›´æœ‰éŸµå‘³çš„åç¾æ–‡æœ¬ã€‚è¦æ±‚ï¼š
1. ä¸¥æ ¼ä¿ç•™åŸæ–‡çš„äº‹å®ä¸æƒ…èŠ‚ï¼Œä¸æ–°å¢ä¿¡æ¯ã€‚
2. ç”¨æ›´è®²ç©¶çš„è¯æ±‡ã€å¥å¼å’Œå¤é›…çš„è¡¨è¾¾ï¼Œè®©è¯­è¨€æ›´æœ‰æ°”éŸµï¼Œä½†ä¿æŒå¯è¯»æ€§ã€‚
3. è¾“å‡ºä¿æŒä¸ºä¸­æ–‡æ®µè½ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚"""

TRAIN_USER_TEMPLATE = "è¯·å°†ä»¥ä¸‹ç°ä»£ç™½è¯æ¶¦è‰²æˆé›…è‡´çš„æ–‡å­¦æ–‡æœ¬ï¼š\n\n{text}"


def call_deepseek(text: str, api_config: dict, retry=3):
    """è°ƒç”¨DeepSeek APIæ”¹å†™æ–‡æœ¬"""
    for attempt in range(retry):
        try:
            response = requests.post(
                f"{api_config['generation']['base_url']}/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_config['generation']['api_key']}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": api_config["generation"]["model"],
                    "messages": [
                        {"role": "system", "content": REWRITE_SYSTEM},
                        {"role": "user", "content": USER_TEMPLATE.format(text=text)}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 2000
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"].strip()
            else:
                print(f"APIé”™è¯¯ {response.status_code}: {response.text}")
                if attempt < retry - 1:
                    time.sleep(2 ** attempt)
                    continue
                return None
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt+1}/{retry}): {e}")
            if attempt < retry - 1:
                time.sleep(2 ** attempt)
                continue
            return None
    return None


def main():
    parser = argparse.ArgumentParser(description="æ‰¹é‡å°†å¼ æ¨æ°´æ–‡æœ¬æ”¹å†™ä¸ºç°ä»£ç™½è¯æ–‡")
    parser.add_argument("--input", default="data/dataset/zhang_cleaned_new.jsonl", help="è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", default="data/modern_pairs_chunks", help="è¾“å‡ºç›®å½•ï¼ˆå­˜å‚¨åˆ†å—æ–‡ä»¶ï¼‰")
    parser.add_argument("--count", type=int, default=None, help="ç”Ÿæˆæ ·æœ¬æ•°é‡ï¼ˆNone=å…¨éƒ¨ï¼‰")
    parser.add_argument("--chunk_size", type=int, default=100, help="æ¯ä¸ªåˆ†å—æ–‡ä»¶çš„å¤§å°")
    parser.add_argument("--workers", type=int, default=10, help="å¹¶å‘è¯·æ±‚æ•°é‡")
    parser.add_argument("--start_from", type=int, default=0, help="ä»ç¬¬å‡ ä¸ªæ ·æœ¬å¼€å§‹å¤„ç†")
    args = parser.parse_args()

    input_file = Path(args.input)
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # åŠ è½½APIé…ç½®
    api_config = json.load(open("data_prep/llm_config.json", encoding="utf-8"))

    print(f"è¯»å–æ•°æ®: {input_file}")
    with open(input_file, 'r', encoding='utf-8') as f:
        records = [json.loads(line) for line in f]

    print(f"æ€»è®°å½•æ•°: {len(records)}")
    
    # ç¡®å®šè¦å¤„ç†çš„æ ·æœ¬æ•°é‡
    if args.count is None:
        sample_size = len(records)
    else:
        sample_size = min(args.count, len(records))
    
    # æ£€æŸ¥å·²æœ‰çš„åˆ†å—æ–‡ä»¶ï¼Œç¡®å®šä»å“ªé‡Œç»§ç»­
    existing_chunks = sorted(output_dir.glob("chunk_*.jsonl"))
    if existing_chunks and args.start_from == 0:
        last_chunk = existing_chunks[-1]
        # ä»æ–‡ä»¶åæå–æœ€åä¸€ä¸ªchunkçš„ç¼–å·ï¼ˆchunk_0000.jsonl -> 0ï¼‰
        last_chunk_num = int(last_chunk.stem.split("_")[1])
        args.start_from = (last_chunk_num + 1) * args.chunk_size
        print(f"ğŸ“‚ æ£€æµ‹åˆ°å·²æœ‰ {len(existing_chunks)} ä¸ªåˆ†å—æ–‡ä»¶")
        print(f"âœ“ ä»ç´¢å¼• {args.start_from} ç»§ç»­å¤„ç†")
    
    if args.start_from >= sample_size:
        print(f"\nâœ… æ‰€æœ‰æ ·æœ¬å·²å®Œæˆï¼")
        return
    
    print(f"\nğŸ“Š ä»»åŠ¡ç»Ÿè®¡:")
    print(f"  ç›®æ ‡æ ·æœ¬æ•°: {sample_size}")
    print(f"  èµ·å§‹ä½ç½®: {args.start_from}")
    print(f"  å‰©ä½™æ ·æœ¬: {sample_size - args.start_from}")
    print(f"  åˆ†å—å¤§å°: {args.chunk_size}")
    print(f"  å¹¶å‘æ•°: {args.workers}")
    print(f"\nğŸš€ å¼€å§‹å¤„ç†...\n")

    def process_record(idx: int, record: dict):
        original_text = record['text']
        modern_text = call_deepseek(original_text, api_config)
        return {
            "index": idx,
            "record_id": record.get("_id", f"zhang_clean_{idx}"),
            "original": original_text,
            "modern": modern_text
        }

    futures = {}
    results_dict = {}  # key=ç´¢å¼•ï¼Œvalue=ç»“æœé¡¹
    chunk_num = args.start_from // args.chunk_size
    
    with ThreadPoolExecutor(max_workers=max(1, args.workers)) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        for idx in range(args.start_from, sample_size):
            futures[executor.submit(process_record, idx, records[idx])] = idx

        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(futures):
            idx = futures[future]
            sample_no = idx + 1
            
            print(f"å¤„ç†æ ·æœ¬ {sample_no}/{sample_size} (idx={idx})...")
            
            try:
                result = future.result()
            except Exception as exc:
                print(f"âœ— å‘ç”Ÿå¼‚å¸¸: {exc}\n")
                continue

            original_text = result["original"]
            modern_text = result["modern"]

            if modern_text:
                print(f"âœ“ æ”¹å†™æˆåŠŸ")
                print(f"  åŸæ–‡ç‰‡æ®µ: {original_text[:60]}...")
                print(f"  ç°ä»£æ–‡ç‰‡æ®µ: {modern_text[:60]}...")
                print(f"  é•¿åº¦å¯¹æ¯”: {len(original_text)} â†’ {len(modern_text)} å­— ({len(modern_text)/len(original_text):.1%})")

                finetune_user_prompt = TRAIN_USER_TEMPLATE.format(text=modern_text)
                item = {
                    "source_index": result["index"],
                    "record_id": result["record_id"],
                    "conversations": [
                        {"role": "system", "content": TRAIN_SYSTEM},
                        {"role": "user", "content": finetune_user_prompt},
                        {"role": "assistant", "content": original_text}
                    ]
                }
                
                results_dict[result["index"]] = item
                
                # ğŸ”‘ æ¯ç´¯ç§¯chunk_sizeä¸ªç»“æœå°±ä¿å­˜ä¸€ä¸ªchunk
                if len(results_dict) >= args.chunk_size:
                    # æ‰¾å‡ºå½“å‰å­—å…¸ä¸­æœ€å°å’Œæœ€å¤§çš„ç´¢å¼•ï¼Œç¡®å®šchunkç¼–å·
                    min_idx = min(results_dict.keys())
                    current_chunk = min_idx // args.chunk_size
                    
                    chunk_file = output_dir / f"chunk_{current_chunk:04d}.jsonl"
                    
                    # æŒ‰ç´¢å¼•æ’åºåå†™å…¥
                    sorted_indices = sorted(results_dict.keys())
                    with open(chunk_file, 'w', encoding='utf-8') as f:
                        for i in sorted_indices:
                            f.write(json.dumps(results_dict[i], ensure_ascii=False) + "\n")
                    
                    print(f"ğŸ’¾ ä¿å­˜åˆ†å—æ–‡ä»¶: {chunk_file} ({len(results_dict)} ä¸ªæ ·æœ¬)\n")
                    results_dict.clear()
                    chunk_num = current_chunk + 1
            else:
                print(f"âœ— æ”¹å†™å¤±è´¥\n")
    
    # ä¿å­˜æœ€åå‰©ä½™çš„æ ·æœ¬
    if results_dict:
        min_idx = min(results_dict.keys())
        current_chunk = min_idx // args.chunk_size
        chunk_file = output_dir / f"chunk_{current_chunk:04d}.jsonl"
        
        sorted_indices = sorted(results_dict.keys())
        with open(chunk_file, 'w', encoding='utf-8') as f:
            for i in sorted_indices:
                f.write(json.dumps(results_dict[i], ensure_ascii=False) + "\n")
        print(f"ğŸ’¾ ä¿å­˜æœ€åçš„åˆ†å—æ–‡ä»¶: {chunk_file} ({len(results_dict)} ä¸ªæ ·æœ¬)")
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œåˆå¹¶è„šæœ¬")
    print(f"   python -m data_prep.merge_chunks --input {output_dir} --output data/modern_pairs_final.jsonl")
    
    # æ˜¾ç¤ºå®Œæ•´çš„ç¬¬ä¸€ä¸ªæ ·æœ¬
    if results_dict:
        print(f"\n{'='*80}")
        print(f"æ ·æœ¬ç¤ºä¾‹ (ç´¢å¼•0):")
        print(f"{'='*80}")
        if 0 in results_dict:
            first = results_dict[0]
            conv = first['conversations']
            print(f"\nã€è®°å½•IDã€‘: {first['record_id']}")
            for message in conv:
                role = message['role']
                header = {
                    'system': 'System prompt',
                    'user': 'User prompt',
                    'assistant': 'Assistantè¾“å‡º'
                }[role]
                print(f"\nã€{header}ã€‘:\n{message['content'][:200]}...")


if __name__ == "__main__":
    main()
