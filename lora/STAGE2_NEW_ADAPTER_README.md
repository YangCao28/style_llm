# Stage2 æŒ‡ä»¤å¾®è°ƒä¿®å¤æ–¹æ¡ˆ

## ğŸ” é—®é¢˜è¯Šæ–­

ä½ çš„æ¨¡å‹"å®Œå…¨å­¦ä¹ ä¸åˆ°instruct"çš„æ ¹æœ¬åŸå› ï¼š

### å½“å‰é—®é¢˜
1. **åªæœ‰ä¸€ä¸ª LoRA adapter**ï¼šStage1 è®­ç»ƒçš„ adapter é’ˆå¯¹é£æ ¼æ³¨å…¥è®¾è®¡ï¼ˆè¿ç»­æ–‡æœ¬è¡¥å…¨ï¼‰
2. **è®­ç»ƒæ–¹å¼é”™è¯¯**ï¼šç›´æ¥åœ¨ Stage1 adapter ä¸Šç»§ç»­è®­ç»ƒæŒ‡ä»¤æ•°æ®
3. **èƒ½åŠ›å†²çª**ï¼šé£æ ¼è¡¥å…¨ï¼ˆç»­å†™ï¼‰vs æŒ‡ä»¤éµå¾ªï¼ˆé—®ç­”ï¼‰ä½¿ç”¨ç›¸åŒçš„æƒé‡

### ä¸ºä»€ä¹ˆå¤±æ•ˆ
- Stage1 å­¦åˆ°çš„æ˜¯ï¼š**ç»™å®šæ–‡æœ¬ â†’ ç»­å†™æ›´å¤šç›¸ä¼¼é£æ ¼çš„æ–‡æœ¬**
- Stage2 éœ€è¦çš„æ˜¯ï¼š**ç»™å®šæŒ‡ä»¤ â†’ ç”Ÿæˆå›å¤ â†’ åœæ­¢**
- åœ¨åŒä¸€ä¸ª adapter ä¸Šè®­ç»ƒä¼šå¯¼è‡´**ç¾éš¾æ€§é—å¿˜**æˆ–**èƒ½åŠ›æ··æ·†**

## âœ… è§£å†³æ–¹æ¡ˆ

ä½¿ç”¨ **åŒ adapter æ¶æ„**ï¼š

```
Base Model (Qwen)
    â”œâ”€â”€ Adapter 1: style (Stage1è®­ç»ƒï¼Œå†»ç»“) â†’ é£æ ¼æ³¨å…¥èƒ½åŠ›
    â””â”€â”€ Adapter 2: instruct (Stage2è®­ç»ƒ) â†’ æŒ‡ä»¤éµå¾ªèƒ½åŠ›
```

### ä¼˜åŠ¿
1. **èƒ½åŠ›éš”ç¦»**ï¼šä¸¤ç§ä¸åŒçš„èƒ½åŠ›ä½¿ç”¨ä¸åŒçš„å‚æ•°
2. **æ— å†²çª**ï¼šStyle adapter å†»ç»“ï¼Œä¿ç•™é£æ ¼èƒ½åŠ›ï¼›Instruct adapter æ–°è®­ç»ƒï¼Œå­¦ä¹ æŒ‡ä»¤
3. **æ¨ç†æ—¶å åŠ **ï¼šä¸¤ä¸ª adapter åŒæ—¶æ¿€æ´»ï¼Œæ¨¡å‹æ—¢æœ‰é£æ ¼åˆå¬æŒ‡ä»¤

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. ä½¿ç”¨æ–°è„šæœ¬é‡æ–°è®­ç»ƒ Stage2

```bash
python -m lora.stage2_with_new_adapter \
    --config lora/stage2_new_adapter_config.json
```

### 2. æµ‹è¯•æ–°æ¨¡å‹

ä¿®æ”¹æµ‹è¯•è„šæœ¬åŠ è½½ä¸¤ä¸ª adaptersï¼š

```python
# åŠ è½½ base model
model = AutoModelForCausalLM.from_pretrained(
    "stage2_instruct_new_adapter",  # åŒ…å«ä¸¤ä¸ª adapters
    torch_dtype=torch.bfloat16,
    device_map="auto",
)

# ä¸¤ä¸ª adapters éƒ½ä¼šè‡ªåŠ¨æ¿€æ´»
```

### 3. éªŒè¯æ•ˆæœ

è¿è¡Œæµ‹è¯•ï¼š
```bash
python -m lora.test_stage2_instruction \
    --model_name_or_path stage2_instruct_new_adapter \
    --preset elegant_style
```

æœŸæœ›è¾“å‡ºï¼š
- âœ… éµå¾ªæŒ‡ä»¤æ ¼å¼ï¼ˆsystem/user/assistantï¼‰
- âœ… ä¿æŒé›…è‡´æ–‡å­¦é£æ ¼
- âœ… ç”Ÿæˆå®Œæ¯•ååœæ­¢ï¼ˆä¸ç»§ç»­å¯¹è¯ï¼‰

## ğŸ“Š å¯¹æ¯”

### æ—§æ–¹æ¡ˆï¼ˆå• adapterï¼‰
```
Stage1: [Base Model] + [LoRA-style] â†’ é£æ ¼ç»­å†™
                           â†“ ç»§ç»­è®­ç»ƒï¼ˆé”™è¯¯ï¼ï¼‰
Stage2: [Base Model] + [LoRA-style*] â†’ é£æ ¼ä¸¢å¤±æˆ–æŒ‡ä»¤å¤±æ•ˆ
```

### æ–°æ–¹æ¡ˆï¼ˆåŒ adapterï¼‰
```
Stage1: [Base Model] + [LoRA-style] â†’ é£æ ¼ç»­å†™
                           â†“ å†»ç»“
Stage2: [Base Model] + [LoRA-style(frozen)] + [LoRA-instruct] â†’ ä¸¤ç§èƒ½åŠ›éƒ½æœ‰
```

## ğŸ”§ å…³é”®é…ç½®

### stage2_new_adapter_config.json
```json
{
  "base_model_name": "Qwen/Qwen3-8B-Base",
  "stage1_adapter_path": "stage1_style_injection/checkpoint-531",
  "lora_r": 64,
  "lora_alpha": 128
}
```

- `lora_r`: æ–° adapter çš„ç§©ï¼ˆ64 è¶³å¤Ÿï¼‰
- `lora_alpha`: ç¼©æ”¾å› å­ï¼ˆ128 = 2Ã—rï¼‰

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

### Adapter ç®¡ç†
```python
# è®­ç»ƒæ—¶
model.set_adapter("instruct")  # åªè®­ç»ƒæ–°çš„ instruct adapter
# style adapter è‡ªåŠ¨å†»ç»“ä½†ä¿æŒæ¿€æ´»

# æ¨ç†æ—¶
model.eval()  # ä¸¤ä¸ª adapters éƒ½æ¿€æ´»
# é£æ ¼èƒ½åŠ›æ¥è‡ª style adapter
# æŒ‡ä»¤èƒ½åŠ›æ¥è‡ª instruct adapter
```

### Labels åˆ†å‰²
```python
# âœ… æ­£ç¡®ï¼šåªå¯¹ assistant å›å¤è®¡ç®— loss
labels = [-100] * len(prompt_ids) + full_ids[len(prompt_ids):]

# âŒ é”™è¯¯ï¼šå¯¹æ•´ä¸ªæ–‡æœ¬è®¡ç®— lossï¼ˆæ—§ç‰ˆæœ¬çš„é—®é¢˜ï¼‰
labels = full_ids
```

## ğŸ¯ é¢„æœŸç»“æœ

è®­ç»ƒåçš„æ¨¡å‹åº”è¯¥ï¼š

1. **ç†è§£æŒ‡ä»¤**ï¼šèƒ½åŒºåˆ† system/user/assistant è§’è‰²
2. **ç”Ÿæˆå›å¤**ï¼šæ ¹æ® user æç¤ºç”Ÿæˆå†…å®¹
3. **ä¿æŒé£æ ¼**ï¼šå›å¤å†…å®¹å…·æœ‰é›…è‡´æ–‡å­¦é£æ ¼ï¼ˆæ¥è‡ª Stage1ï¼‰
4. **æ­£ç¡®åœæ­¢**ï¼šç”Ÿæˆ `<|im_end|>` ååœæ­¢ï¼Œä¸ç»§ç»­å¯¹è¯

## ğŸ› å¦‚æœè¿˜ä¸work

æ£€æŸ¥ï¼š
1. Stage1 checkpoint æ˜¯å¦æ­£ç¡®ï¼ˆç¡®è®¤æœ‰é£æ ¼èƒ½åŠ›ï¼‰
2. æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆconversations æ ¼å¼ï¼‰
3. Tokenizer çš„ special tokens é…ç½®
4. è®­ç»ƒ loss æ˜¯å¦ä¸‹é™

æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼š
```bash
# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡º
[step 5] loss = 2.1234
[step 10] loss = 1.8765
...
```

å¦‚æœ loss ä¸ä¸‹é™ â†’ æ£€æŸ¥æ•°æ®å’Œ labels
å¦‚æœ loss ä¸‹é™ä½†æ¨ç†ä¸å¯¹ â†’ æ£€æŸ¥ adapter åŠ è½½å’Œæ¿€æ´»
