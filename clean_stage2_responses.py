"""æ¸…ç† Stage2 è®­ç»ƒæ•°æ®ä¸­ assistant å›å¤çš„"å°¾å·´"

é—®é¢˜ï¼šè®­ç»ƒæ•°æ®ä¸­å¯èƒ½åŒ…å«ä»¥ä¸‹æ— ç”¨åç¼€ï¼š
- "æ”¹å†™å®Œæˆ"
- "è¯·å‚è€ƒ"
- "ä»¥ä¸Šæ˜¯æ”¹å†™ç»“æœ"
- ç­‰ç­‰

è¿™äº›"å°¾å·´"ä¼šè®©æ¨¡å‹å­¦åˆ°"è¯´è¯ä¸è½å¥"çš„åä¹ æƒ¯ã€‚

Usage:
    python clean_stage2_responses.py \
        --input_path data/stage2_sample_5000.jsonl \
        --output_path data/stage2_sample_5000_cleaned.jsonl
"""

import argparse
import json
import re
from pathlib import Path


# éœ€è¦æ¸…ç†çš„å¸¸è§åç¼€æ¨¡å¼
TAIL_PATTERNS = [
    r"æ”¹å†™å®Œæˆ[ã€‚ï¼\.!]*$",
    r"è¯·å‚è€ƒ[ã€‚ï¼\.!]*$",
    r"ä»¥ä¸Šæ˜¯æ”¹å†™ç»“æœ[ã€‚ï¼\.!]*$",
    r"æ”¹å†™å¦‚ä¸‹[ï¼š:ã€‚ï¼\.!]*$",
    r"ä¾›æ‚¨å‚è€ƒ[ã€‚ï¼\.!]*$",
    r"å¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©[ã€‚ï¼\.!]*$",
    r"è°¢è°¢[ã€‚ï¼\.!]*$",
    r"è¿˜æœ‰å…¶ä»–é—®é¢˜å—[ï¼Ÿ?ã€‚ï¼\.!]*$",
    r"[\n\s]+$",  # ç»“å°¾çš„å¤šä½™ç©ºç™½
]


def clean_assistant_response(response: str) -> str:
    """æ¸…ç† assistant å›å¤ä¸­çš„å°¾å·´"""
    original = response
    cleaned = response.strip()
    
    # åº”ç”¨æ‰€æœ‰æ¸…ç†æ¨¡å¼
    for pattern in TAIL_PATTERNS:
        cleaned = re.sub(pattern, "", cleaned, flags=re.IGNORECASE)
    
    # å†æ¬¡å»é™¤å°¾éƒ¨ç©ºç™½
    cleaned = cleaned.strip()
    
    # å¦‚æœæ¸…ç†åå˜åŒ–äº†ï¼Œè®°å½•ä¸€ä¸‹
    if cleaned != original:
        return cleaned, True
    return cleaned, False


def clean_dataset(input_path: Path, output_path: Path):
    """æ¸…ç†æ•´ä¸ªæ•°æ®é›†"""
    print(f"ğŸ“– è¯»å–: {input_path}")
    
    samples = []
    with input_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                samples.append(json.loads(line))
    
    print(f"âœ“ åŠ è½½äº† {len(samples):,} ä¸ªæ ·æœ¬")
    
    # æ¸…ç†æ¯ä¸ªæ ·æœ¬
    cleaned_count = 0
    for sample in samples:
        conversations = sample.get("conversations", [])
        for msg in conversations:
            role = msg.get("role") or msg.get("from")
            if role in ("assistant", "gpt", "bot"):
                content = msg.get("content") or msg.get("value") or ""
                cleaned_content, changed = clean_assistant_response(content)
                
                if changed:
                    cleaned_count += 1
                    # æ›´æ–°å†…å®¹
                    if "content" in msg:
                        msg["content"] = cleaned_content
                    if "value" in msg:
                        msg["value"] = cleaned_content
    
    print(f"âœ“ æ¸…ç†äº† {cleaned_count} ä¸ª assistant å›å¤")
    
    # ä¿å­˜
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        for sample in samples:
            f.write(json.dumps(sample, ensure_ascii=False) + "\n")
    
    print(f"âœ“ ä¿å­˜åˆ°: {output_path}")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(samples):,}")
    print(f"  æ¸…ç†æ ·æœ¬æ•°: {cleaned_count:,}")
    print(f"  æ¸…ç†æ¯”ä¾‹: {cleaned_count / len(samples) * 100:.1f}%")


def main():
    parser = argparse.ArgumentParser(description="æ¸…ç† Stage2 è®­ç»ƒæ•°æ®ä¸­çš„å°¾å·´")
    parser.add_argument(
        "--input_path",
        type=Path,
        required=True,
        help="è¾“å…¥çš„ JSONL æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--output_path",
        type=Path,
        required=True,
        help="è¾“å‡ºçš„æ¸…ç†å JSONL æ–‡ä»¶è·¯å¾„",
    )
    
    args = parser.parse_args()
    
    if not args.input_path.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_path}")
        return
    
    clean_dataset(args.input_path, args.output_path)


if __name__ == "__main__":
    main()
